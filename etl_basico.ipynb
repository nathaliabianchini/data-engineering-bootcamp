{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jar_path = os.path.abspath(\"./conector_dll/mssql-jdbc-13.2.1.jre11.jar\")\n",
    "dll_path = os.path.abspath(\"./conector_dll/mssql-jdbc_auth-13.2.1.x64.dll\")  \n",
    "\n",
    "os.environ[\"PATH\"] = os.path.dirname(dll_path) + os.pathsep + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"storeToClean\") \\\n",
    "    .config(\"spark.jars\", jar_path) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ba348",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"./dataset_files/store.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acecc8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = spark.read.csv(csv_path, header = \"True\")\n",
    "store_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2544a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Schema = StructType([\n",
    "    StructField('Store', StringType(), nullable=True),\n",
    "    StructField('StoreType', StringType(), nullable=True),\n",
    "    StructField('Assortment', StringType(), nullable=True),\n",
    "    StructField('CompetitionDistance', FloatType(), nullable=True),\n",
    "    StructField('CompetitionOpenSinceMonth', IntegerType(), nullable=True),\n",
    "    StructField('CompetitionOpenSinceYear', IntegerType(), nullable=True),\n",
    "    StructField('Promo2', IntegerType(), nullable=True),\n",
    "    StructField('Promo2SinceWeek', IntegerType(), nullable=True),\n",
    "    StructField('Promo2SinceYear', IntegerType(), nullable=True),\n",
    "    StructField('PromoInterval', StringType(), nullable=True),\n",
    "])\n",
    "\n",
    "df = spark.read.option(\"header\", True).option(\"mode\", \"DROPMALFORMED\").schema(Schema).csv(csv_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7216c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed93c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(value=0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97981b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"url\", \"jdbc:sqlserver://localhost:1433;databaseName=Datasets;integratedSecurity=true;encrypt=true;trustServerCertificate=true;\") \\\n",
    "    .option(\"dbtable\", \"dbo.ETLBasico\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark-project)",
   "language": "python",
   "name": "spark-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
